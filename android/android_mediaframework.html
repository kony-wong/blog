<!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>架构资料</title>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
        <link href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css" rel="stylesheet" type="text/css">
        <style>
.task-list-item { list-style-type: none; } .task-list-item-checkbox { margin-left: -20px; vertical-align: middle; }
</style>
        <style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        
        <script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script>
    </head>
    <body class="vscode-light">
        <h2 id="%e6%9e%b6%e6%9e%84%e8%b5%84%e6%96%99">架构资料</h2>
<p><a href="Android_MultiMedia_ybx.pdf">架构参考资料</a></p>
<hr>
<p>NuPlayer部分，关注NuPlayer这一播放器引擎的概要实现</p>
<hr>
<h2 id="nuplayer%e7%b3%bb%e7%bb%9f%e6%9e%84%e6%88%90">NuPlayer系统构成</h2>
<p><img src="file:////Users/a/konyProject/blog/android/images/nuplayer_overview.png" alt="NuPlayer系统概要构成图"></p>
<p><strong>NuPlayerDecoder</strong></p>
<blockquote>
<p>对MediaCodec的封装，MediaCodec又进而使用ACodec，完成了解码的逻辑控制，真正的解码在OMX中</p>
</blockquote>
<p><strong>NuPlayerSource</strong></p>
<blockquote>
<p>封装了数据源读取、Parse/Demux的功能，它对外输出音频压缩数据和视频压缩数据。源文件是将Audio和Video压缩数据后加上metadata，Demux功能就是读取metadata，从其中抽取audio/video压缩数据流，送入NuPlayerDecoder</p>
</blockquote>
<p><strong>NuPlayerRenderer</strong></p>
<blockquote>
<p>控制音视频的输出
Renderer的作用就是根据传过来数据帧的时间来判断这一帧是否需要渲染，并进行音视频的同步。但是真正硬件渲染的代码在MediaCodec和ACodec中</p>
</blockquote>
<p><strong>Tips</strong></p>
<blockquote>
<p>NuPlayer、NuPlayerDecoder、NuPlayerRenderer、NuPlayerSource配合实现了<strong>播放器框架</strong>，它不涉及具体的编码、Mux、Demux、Render具体处理逻辑，主要是完成控制流逻辑，NuPlayer是一个连接器，构建NuPlayer**各个组件的连接和通信。</p>
</blockquote>
<blockquote>
<p>NuPlayer利用MediaCodec、MediaExtrator、MediaMux等组件提供的软硬件统一抽象接口，为MediaPlayService提供具体的播放接口实现(setDataSource-&gt;prepare-&gt;start-&gt;seek-&gt;pause-&gt;stop...)</p>
</blockquote>
<blockquote>
<p>MediaPlayService实现了多种播放器的路由选择，比如Android7.0之前AwesomePlayer(local file)、NuPlayer(rtsp、http)的选择与适配。</p>
</blockquote>
<hr>
<h3 id="%e6%a0%b8%e5%bf%83%e7%bb%84%e4%bb%b6mediacodec">核心组件MediaCodec</h3>
<p>官方参考资料：MeidaCodec API: <a href="https://developer.android.com/reference/android/media/MediaCodec">https://developer.android.com/reference/android/media/MediaCodec</a></p>
<p>官方的虽然是Java的，但是从实现上，Java是对Native的简单封装，其接口的功能未变化，所以可以参考</p>
<p>MediaCodec是一个Codec，通过硬件加速解码和编码。它为芯片厂商和应用开发者搭建了一个统一接口。MediaCodec几乎是所有安卓播放器硬解的标配，它同MediaExtractor、MediaMuxer等构成NDK级别的接口层，在MediaCodec内部使用ACodec实现具体的数据解码处理。MediaCodec是可以独立使用的，只要按照接口的调用要求来调用</p>
<p>MediaCodec可以处理的数据有以下三种类型：压缩数据、原始音频数据、原始视频数据。这三种类型的数据均可以利用ByteBuffers进行处理，但是对于原始视频数据应提供一个Surface以提高编解码器的性能。Surface直接使用native视频数据缓存，而没有映射或复制它们到ByteBuffers，因此，这种方式会更加高效。</p>
<p>MediaCodec采用异步方式处理数据，并且使用了一组输入输出缓存（ByteBuffer）。通过请求一个空的输入缓存（ByteBuffer），向其中填充满数据并将它传递给编解码器处理。编解码器处理完这些数据并将处理结果输出至一个空的输出缓存（ByteBuffer）中。使用完输出缓存的数据之后，将其释放回编解码器：示意图如下。MediaCodec将Codec和输入·输出Buffer作为一个统一概念来管理</p>
<p><img src="file:////Users/a/konyProject/blog/android/images/mediacodec_overview.png" alt=""></p>
<hr>
<h3 id="%e7%bb%84%e4%bb%b6%e5%9b%be">组件图</h3>
<p><img src="file:////Users/a/konyProject/blog/android/images/nuplayer_component_dia.jpg" alt=""></p>
<h3 id="mainusecase">mainUseCase</h3>
<p>通过查询网络上已经有的时序图，能够基本清晰的看到完整的主要时序
这里主要关注NuPlayer**组件间的互动，而NuPlayerDecoder和MediaCodec等的互动不作为重点</p>
<p><strong>初始化流程</strong></p>
<p><img src="file:////Users/a/konyProject/blog/android/images/nuplayer_init_flow.jpg" alt=""></p>
<ul>
<li>NuPlayerDriver
提供了同期接口和状态机管理</li>
<li>NuPlayer
面向NuPlayerDriver提供了异步接口函数，在异步接口函数内部，使用AMessage\AHandler\ALooper的处理机制来提供异步</li>
<li>NuPlayer启动过程中
<ul>
<li>调用NuPlayerSource的Start函数</li>
<li>调用NuPlayerDecoder的Init和Configure函数，进而调用CreateByType/CreateByComponentName来创建MediaCodec</li>
</ul>
</li>
</ul>
<p><strong>emptyBuffer</strong></p>
<ul>
<li>NuPlayerDecoder受到MediaCodec触发(CB_INPUT_AVAILABLE),开始准备数据，准备完成后调用MediaCodec的queueInputBuffer接口送入数据，这个CB_INPUT_AVAILABLE是NuPlayerDecoder自主定义的，代表着MediaCodec的数据请求</li>
<li>NuPlayerDecoder和NuPlayerSource(GenericSource/StreamSource/HttpSource)交互(通过dequeueAccessUnit)，在onInputBufferFetched中响应数据准备完成的请求</li>
<li>NuPlayerSource做数据准备动作</li>
</ul>
<p><img src="file:////Users/a/konyProject/blog/android/images/nuplayer_empty_buffer_flow.jpg" alt=""></p>
<ul>
<li>数据量:只要能从MediaCodec申请到InputBuffer就可以送入</li>
</ul>
<p><strong>fillbuffer</strong></p>
<ul>
<li>NuPlayerDecoder收到MediaCodec触发的CB_OUTPUT_AVAILABLE通知，了解MediaCodec已经完成了部分数据的解码操作，即在OutputBuffer中可以获取到解码后的数据，</li>
<li>通知NuPlayerRenderer做准备，获取解码后的数据，进行下一步的渲染动作。</li>
<li>当数据被NuPlayerRenderer读取完成后，NuPlayerDecoder会调用releaseOutputBuffer，通知MediaCodec数据已经消费完，outputBuffer可以继续使用了。</li>
</ul>
<p><img src="file:////Users/a/konyProject/blog/android/images/nuplayer_fillbuffer_flow.jpg" alt=""></p>
<h3 id="%e6%80%bb%e7%bb%93">总结</h3>
<blockquote>
<p>emptyBuffer和fillBuffer的处理流程中，在从Source向Decoder准备数据的时候，会拷贝压缩的音频/视频数据。在解码完成后，未压缩的视频/音频数据，数据量是很大，这里没有发生数据拷贝动作，这里只是获取数据的元数据信息，完成数据流的控制。所以到解码完成后的数据渲染处理都是在MediaCodec-&gt;ACodec和OMX以及Surface等的配置来实现的</p>
</blockquote>
<blockquote>
<p>NuPlayer的实现逻辑由四个部分构成</p>
<ul>
<li>初始化构建，启动、停止、Seek的控制指令实现</li>
<li>播放过程中，会完全由MediaCodec作为核心引擎来驱动emptyBuffer和fillBuffer过程</li>
<li>在播放过程中响应异常处理，解码错误、EOS等</li>
<li>在播放过程中的音视频同步控制逻辑</li>
</ul>
</blockquote>
<hr>
<p>多媒体框架部分，从整体上来分析Android的MediaFramework</p>
<hr>
<h2 id="%e5%a4%9a%e5%aa%92%e4%bd%93%e6%a1%86%e6%9e%b6">多媒体框架</h2>
<h3 id="c-s%e6%9e%b6%e6%9e%84">C-S架构</h3>
<p><img src="file:////Users/a/konyProject/blog/android/images/media_framwork_cs_arch.png" alt=""></p>
<ul>
<li>MediaplayerService实现了bind服务端，NDK和SDK(JNI)为bind客户端</li>
<li>MediaPlayerService主要实现了NuPlayer，同时动态链接stageFright库(使用mediacodec、acodec等组件接口)。真正在底层干活的如MediaCodecService，SurfaceFlinger，AudioFlinger，MediaExtractorService又以bind服务的形式提供</li>
<li>Android Application使用NDK、SDK来实现Media访问</li>
</ul>
<h3 id="client%e7%ab%afmediandk">Client端(MediaNDK)</h3>
<p><strong>依赖库构成</strong></p>
<pre><code><div>LOCAL_SHARED_LIBRARIES := \
    libbinder \
    libmedia \ 这里可以暂时理解到libmedia提供的bindproxy，仍然会被NDK使用
    libmediadrm \
    libstagefright \
    libstagefright_foundation \
    liblog \
    libutils \
    libcutils \
    libandroid_runtime \
    libbinder \
    libgui \
    libui \
</div></code></pre>
<p><strong>NDK对外提供的组件</strong></p>
<ul>
<li>MediaCrypto</li>
<li>MediaCodec</li>
<li>MediaDrm</li>
<li>MediaExtrator</li>
<li>MediaFormat</li>
<li>MediaMuxer</li>
</ul>
<p>NDK使用libstagefright里的组件来实现NDK的Media**组件，比如MediaCodec，可以在代码中看到有明确的
sp<a href="android::MediaCodec">android::MediaCodec</a> mCodec的封装引用。</p>
<pre><code><div>struct AMediaCodec {
    sp&lt;android::MediaCodec&gt; mCodec;★★★
    sp&lt;ALooper&gt; mLooper;
    sp&lt;CodecHandler&gt; mHandler;
    sp&lt;AMessage&gt; mActivityNotification;
    int32_t mGeneration;
    bool mRequestedActivityNotification;
    OnCodecEvent mCallback;
    void *mCallbackUserData;
};
</div></code></pre>
<h3 id="client%e7%ab%aflibmediajnijdk">Client端(libMedia_jni(JDK))</h3>
<p>base/media/jni/*</p>
<p><strong>依赖的库列表</strong></p>
<p>LOCAL_SHARED_LIBRARIES := <br>
libandroid_runtime <br>
libnativehelper <br>
libutils <br>
libbinder <br>
libmedia <br>
libmediadrm <br>
libskia <br>
libui <br>
liblog <br>
libcutils <br>
libgui <br>
libstagefright <br>
libstagefright_foundation <br>
libcamera_client <br>
libmtp <br>
libusbhost <br>
libexif <br>
libpiex <br>
libstagefright_amrnb_common</p>
<p><strong>JDK对外开放的接口</strong></p>
<p>JDK(JNI)和NDK类似，即开放了MediaPlayer等统合的接口，也开放的基础的组件接口如MediaCodec</p>
<ul>
<li>android_media_MediaCodec：这里依赖了libstagefright中的MediaCodec</li>
<li>android_media_MediaCodecList</li>
<li>android_media_MediaCrypto</li>
<li>android_media_MediaDataSource</li>
<li>android_media_MediaDrm</li>
<li>android_media_MediaExtractor</li>
<li>android_media_MediaMuxer</li>
<li>android_media_MediaPlayer:这里依赖了libMedia中的mediaplayer</li>
<li>android_media_MediaRecorder</li>
<li>android_media_MediaScanner</li>
<li>android_media_MediaSync</li>
</ul>
<p>tips:</p>
<blockquote>
<p>通过查看**native_setup查看new出来的对象是哪个类的，进而决定其具体实现
通过查看JNI_onLoad,可以查看Java里面的接口和android_media_***之间的接口映射关系</p>
</blockquote>
<h3 id="c-s%e7%ab%af%e9%80%9a%e4%bf%a1bind">C-S端通信(bind)</h3>
<p>问题：MediaPlayer怎么实现的通信呢？</p>
<p><strong>media.player的Client构建</strong></p>
<p>android_media_MediaPlayer中调用了new MediaPlayer</p>
<p>MediaPlayer的声明</p>
<pre><code><div>class MediaPlayer : public BnMediaPlayerClient,
                    public virtual IMediaDeathNotifier
</div></code></pre>
<p>后续的接口如setVideoSurface、prepare都是调用的MediaPlayer的对应接口</p>
<p>这里以setDataSource为例：</p>
<pre><code class="language-cpp"><div><span class="hljs-keyword">status_t</span> MediaPlayer::setDataSource(
        <span class="hljs-keyword">const</span> sp&lt;IMediaHTTPService&gt; &amp;httpService,
        <span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span> *url, <span class="hljs-keyword">const</span> KeyedVector&lt;String8, String8&gt; *headers)
{
    ALOGV(<span class="hljs-string">"setDataSource(%s)"</span>, url);
    <span class="hljs-keyword">status_t</span> err = BAD_VALUE;
    <span class="hljs-keyword">if</span> (url != <span class="hljs-literal">NULL</span>) {
        <span class="hljs-keyword">const</span> sp&lt;IMediaPlayerService&gt; service(getMediaPlayerService());
        <span class="hljs-keyword">if</span> (service != <span class="hljs-number">0</span>) {
            sp&lt;IMediaPlayer&gt; player(service-&gt;create(<span class="hljs-keyword">this</span>, mAudioSessionId));
            <span class="hljs-keyword">if</span> ((NO_ERROR != doSetRetransmitEndpoint(player)) ||
                (NO_ERROR != player-&gt;setDataSource(httpService, url, headers))) {
                player.clear();
            }
            err = attachNewPlayer(player);
        }
    }
    <span class="hljs-keyword">return</span> err;
}
</div></code></pre>
<p>这里关键的const sp<IMediaPlayerService> service(getMediaPlayerService());，这里构建IMediaPlayerService，进而使用IMediaPlayerService的create函数来创建player。
<em>目前函数调用还处于jni的Context内</em></p>
<p>查看getMediaPlayerService，就是访问defaultServiceManager，获取到media.player的bind客户端
进而建立和MediaPlayerService的bind关联</p>
<pre><code class="language-cpp"><div><span class="hljs-comment">/*static*/</span><span class="hljs-keyword">const</span> sp&lt;IMediaPlayerService&gt;
IMediaDeathNotifier::getMediaPlayerService()
{
    ALOGV(<span class="hljs-string">"getMediaPlayerService"</span>);
    Mutex::Autolock _l(sServiceLock);
    <span class="hljs-keyword">if</span> (sMediaPlayerService == <span class="hljs-number">0</span>) {
        sp&lt;IServiceManager&gt; sm = defaultServiceManager();
        sp&lt;IBinder&gt; binder;
        <span class="hljs-keyword">do</span> {
            binder = sm-&gt;getService(String16(<span class="hljs-string">"media.player"</span>));
            <span class="hljs-keyword">if</span> (binder != <span class="hljs-number">0</span>) {
                <span class="hljs-keyword">break</span>;
            }
            ALOGW(<span class="hljs-string">"Media player service not published, waiting..."</span>);
            usleep(<span class="hljs-number">500000</span>); <span class="hljs-comment">// 0.5 s</span>
        } <span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>);

        <span class="hljs-keyword">if</span> (sDeathNotifier == <span class="hljs-literal">NULL</span>) {
            sDeathNotifier = <span class="hljs-keyword">new</span> DeathNotifier();
        }
        binder-&gt;linkToDeath(sDeathNotifier);
        sMediaPlayerService = interface_cast&lt;IMediaPlayerService&gt;(binder);
    }
    <span class="hljs-keyword">return</span> sMediaPlayerService;
}
</div></code></pre>
<p>经过上述处理，建立了MediaPlayer的Client端，参考下面的服务端，mediaServer能够看到，在mediaServer启动的时候，注册了mediaplayerservice的bind服务。</p>
<p><img src="file:////Users/a/konyProject/blog/android/images/media_framwork_cs_flow.png" alt=""></p>
<p>※我目前解析的结果和图中的稍有偏差，不影响当前的理解，暂时不再深究</p>
<h3 id="server%e7%ab%afmediaserver">Server端(mediaServer))</h3>
<p>av/media/mediaserver/main_mediaserver.cpp</p>
<pre><code class="language-cpp"><div><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc __unused, <span class="hljs-keyword">char</span> **argv __unused)</span>
</span>{
    signal(SIGPIPE, SIG_IGN);

    sp&lt;ProcessState&gt; proc(ProcessState::self());
    sp&lt;IServiceManager&gt; sm(defaultServiceManager());
    ALOGI(<span class="hljs-string">"ServiceManager: %p"</span>, sm.get());
    InitializeIcuOrDie();
    MediaPlayerService::instantiate();★这里做了media.player bind服务端注册
    ResourceManagerService::instantiate();
    registerExtensions();
    ProcessState::self()-&gt;startThreadPool();
    IPCThreadState::self()-&gt;joinThreadPool();
}

<span class="hljs-keyword">void</span> MediaPlayerService::instantiate() {
    defaultServiceManager()-&gt;addService(
            String16(<span class="hljs-string">"media.player"</span>), <span class="hljs-keyword">new</span> MediaPlayerService());
}

这里请留意，<span class="hljs-keyword">new</span>出来的MediaPlayerService的对象。

</div></code></pre>
<p><strong>mediaServer依赖的库</strong></p>
<pre><code><div>LOCAL_SHARED_LIBRARIES := \
	libcamera_metadata \
	libcamera_client \
	libcameraservice \
	libresourcemanagerservice \
	libcutils \
	libmedia \
	libmediaplayerservice \ ★这里依赖了和辛苦mediaplayerService
	libutils \
	libbinder \
	libicuuc \

LOCAL_STATIC_LIBRARIES := \
        libicuandroid_utils \
        libregistermsext

LOCAL_MODULE:= mediaserver
</div></code></pre>
<h3 id="server%e7%ab%aflibmediaplayerservice">Server端(libmediaplayerservice)</h3>
<p>av/media/libmediaplayerservice</p>
<p><strong>依赖的库</strong></p>
<pre><code><div>LOCAL_SHARED_LIBRARIES :=       \
    libbinder                   \
    libcamera_client            \
    libcrypto                   \
    libcutils                   \
    libdrmframework             \
    liblog                      \
    libdl                       \
    libgui                      \ 主要是Surface使用
    libmedia                    \ 提供Binder使用的Proxy库，为JNI接口提供访问
    libmediautils               \
    libmemunreachable           \
    libsonivox                  \
    libstagefright              \ 具体的MediaCodec，即具体用来做解码等处理的组件库，包括ACodec，OMXCodec，继承了OpenMaxIL组件
    libstagefright_foundation   \ 基础类如AHandle
    libstagefright_httplive     \
    libstagefright_omx          \
    libstagefright_wfd          \
    libutils                    \
    libvorbisidec               \

LOCAL_STATIC_LIBRARIES :=       \
    libstagefright_nuplayer     \构建在Android7.0版本使用的NuPlayer
    libstagefright_rtsp         \
    libstagefright_timedtext    \
</div></code></pre>
<p><strong>MediaPlayService对外提供的接口</strong></p>
<p>MediaPlayService对外封装的是统一的MediaPlayer等接口,作为media.play服务的总入口
面向JNI实现bind服务</p>
<pre><code><div>LOCAL_SRC_FILES:=               \
    ActivityManager.cpp         \
    HDCP.cpp                    \
    MediaPlayerFactory.cpp      \ 根据文件扩展名等特性来创建关联的Player
    MediaPlayerService.cpp      \ 提供Bind-Service访问接口
    MediaRecorderClient.cpp     \
    MetadataRetrieverClient.cpp \
    RemoteDisplay.cpp           \
    StagefrightRecorder.cpp     \
    TestPlayerStub.cpp          \
</div></code></pre>
<p>从Mediaplayerservice的源文件构成能够看到，其主要功能是根据文件类型用来创建MediaPlayerService，目前主要是NuPlayer。</p>
<h3 id="server%e7%ab%afmediacodecservice">Server端(MediaCodecService)</h3>
<p>av/services/mediacodec/**</p>
<pre><code class="language-cpp"><div><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc __unused, <span class="hljs-keyword">char</span>** argv)</span>
</span>{
    ALOGI(<span class="hljs-string">"@@@ mediacodecservice starting"</span>);
    signal(SIGPIPE, SIG_IGN);
    MiniJail();

    <span class="hljs-built_in">strcpy</span>(argv[<span class="hljs-number">0</span>], <span class="hljs-string">"media.codec"</span>);
    sp&lt;ProcessState&gt; proc(ProcessState::self());
    sp&lt;IServiceManager&gt; sm = defaultServiceManager();
    MediaCodecService::instantiate();
    ProcessState::self()-&gt;startThreadPool();
    IPCThreadState::self()-&gt;joinThreadPool();
}
</div></code></pre>
<p>MediaCodecService的继承关系</p>
<pre><code><div>class MediaCodecService : public BinderService&lt;MediaCodecService&gt;, public BnMediaCodecService
</div></code></pre>
<p>这里并没有直接使用defaultServiceManager的addservice来直接注册bind服务，而是使用BinderService里面的publish函数来添加的。通过代码能够很快查看。</p>
<p><strong>依赖的库</strong></p>
<pre><code><div>LOCAL_SHARED_LIBRARIES := libmedia 
    libmediacodecservice ★这里是核心依赖
    libbinder libutils \
	liblog libminijail
LOCAL_C_INCLUDES := \
    $(TOP)/frameworks/av/media/libstagefright \
    $(TOP)/frameworks/native/include/media/openmax
LOCAL_MODULE:= mediacodec
</div></code></pre>
<p><strong>注意</strong>
这里的MediaCodecService和最初想象的MediaCodec类是不一样的。这里只有一个IF：getOMX
由此推定，这里是OMX Codec的bind服务入口，而不是MediaCodec的服务入口。MediaCodec统合进libstagefright库里面，提供了lib库层面的接口服务。</p>
<p><strong>tips</strong></p>
<p>使用bind服务，可以通过服务名来查找，比如media.player查询，能够查找到注册和查询的处理逻辑。</p>
<h2 id="%e5%8f%82%e8%80%83%e9%93%be%e6%8e%a5">参考链接</h2>
<p><a href="https://blog.csdn.net/yanbixing123/article/details/88937193">https://blog.csdn.net/yanbixing123/article/details/88937193</a>
Android音视频处理之MediaCodec <a href="https://www.jianshu.com/p/30e596112015">https://www.jianshu.com/p/30e596112015</a></p>

    </body>
    </html>